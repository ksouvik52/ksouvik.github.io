
+++
title = "Selected Pulications"
description = "Research Papers"
date = "2020-11-03"
aliases = ["publications", "research-papers", "research"]
author = "Souvik Kundu"
+++

### Conferences
1. [[**DATE 2022**](https://www.date-conference.com/)] **S. Kundu**, S. Wang, Q. Sun, P. A. Beerel, M. Pedram, "**BMPQ: Bit-Gradient Sensitivity Driven Mixed Precision Quantization of DNNs from Scratch**".{{< rawhtml >}} <a href="/bibs/BMPQ_DATE2022.bib" target="_blank"><i class="fa fa-quote-right fa-lg"></i></a> <a href="https://arxiv.org/pdf/2112.13843.pdf" target="_blank"><i class="far fa-file-pdf fa-lg"></i></a> {{< /rawhtml >}}.


1. [[**NeurIPS 2021**](https://nips.cc/)] **S. Kundu**, Q. Sun, Y. Fu, M. Pedram, P. A. Beerel, "**Analyzing the Confidentiality of Undistillable Teachers in Knowledge Distillation**".{{< rawhtml >}} <a href="/bibs/Analyzing_NeurIPS2021.bib" target="_blank"><i class="fa fa-quote-right fa-lg"></i></a> <a href="https://proceedings.neurips.cc/paper/2021/file/4ca82782c5372a547c104929f03fe7a9-Paper.pdf" target="_blank"><i class="far fa-file-pdf fa-lg"></i></a> {{< /rawhtml >}}.

1. [[**ICCV 2021**](http://iccv2021.thecvf.com/home)] **S. Kundu**, M. Pedram, P. A. Beerel, "**HIRE-SNN: Harnessing the Inherent Robustness of Deep Spiking Neural Networks by Training with Crafted Input Noise**". {{< rawhtml >}} <a href="/bibs/Hiresnn_ICCV.bib" target="_blank"><i class="fa fa-quote-right fa-lg"></i></a> <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Kundu_HIRE-SNN_Harnessing_the_Inherent_Robustness_of_Energy-Efficient_Deep_Spiking_Neural_ICCV_2021_paper.pdf" target="_blank"><i class="far fa-file-pdf fa-lg"></i></a> {{< /rawhtml >}}.

1. [[**ICASSP 2021**](https://2021.ieeeicassp.org/)] **S. Kundu**, S. Sundaresan, "**AttentionLite: Towards Efficient Self-Attention Models for Vision**”.{{< rawhtml >}} <a href="/bibs/AttentionLite_ICASSP.bib" target="_blank"><i class="fa fa-quote-right fa-lg"></i></a> <a href="https://arxiv.org/pdf/2101.05216.pdf" target="_blank"><i class="far fa-file-pdf fa-lg"></i></a> {{< /rawhtml >}}.

2. [[**WACV 2021**](http://wacv2021.thecvf.com/home)] **S. Kundu**, G.Datta, M. Pedram, P. A. Beerel, "**Spike-Thrift: Towards Energy-Efficient Deep Spiking Neural Networks by Limiting Spiking Activity via Attention-Guided Compression**”.{{< rawhtml >}} <a href="/bibs/spike_thrift_wacv2021.bib" target="_blank"><i class="fa fa-quote-right fa-lg"></i></a> <a href="https://openaccess.thecvf.com/content/WACV2021/papers/Kundu_Spike-Thrift_Towards_Energy-Efficient_Deep_Spiking_Neural_Networks_by_Limiting_Spiking_WACV_2021_paper.pdf" target="_blank"><i class="far fa-file-pdf fa-lg"></i></a> {{< /rawhtml >}}

3. [[**ASP-DAC 2021**](http://www.aspdac.com/aspdac2021/)] **S. Kundu**, M. Nazemi, P. A. Beerel, M. Pedram, "**DNR: A Tunable Robust Pruning Framework Through Dynamic Network Rewiring of DNNs**”.{{< rawhtml >}} <a href="/bibs/DNR_2021.bib" target="_blank"><i class="fa fa-quote-right fa-lg"></i></a> <a href="https://arxiv.org/pdf/2011.03083.pdf" target="_blank"><i class="far fa-file-pdf fa-lg"></i></a> {{< /rawhtml >}}

4. [[**Allerton 2019**](https://allerton.csl.illinois.edu/)] **S. Kundu**, S. Prakash, H. Akrami, P. A. Beerel, K. M. Chugg, "**pSConv: A Pre-defined Sparse Kernel Based Convolution for Deep CNNs**”.{{< rawhtml >}} <a href="/bibs/psconv_allerton2019.bib" target="_blank"><i class="fa fa-quote-right fa-lg"></i></a> <a href="https://arxiv.org/pdf/1910.00724.pdf" target="_blank"><i class="far fa-file-pdf fa-lg"></i></a> {{< /rawhtml >}}

5. [[**IEEE ISEC 2019**](https://isec2019.org/)] **S. Kundu**,  G.Datta, P.A. Beerel, M. Pedram, "**qBSA: Logic Design of a 32-bitBlock-Skewed RSFQ Arithmetic Logic Unit**”.{{< rawhtml >}} <a href="/bibs/qbsa_isec2019.bib" target="_blank"><i class="fa fa-quote-right fa-lg"></i></a> <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8990921" target="_blank"><i class="far fa-file-pdf fa-lg"></i></a> {{< /rawhtml >}}

6. [[**IEEE ISEC 2019**](https://isec2019.org/)] G.Datta, H. Cong, **S. Kundu**, P. A. Beerel, "**qCDC: Metastability-Resilient Synchronization FIFO for SFQ Logic**”.{{< rawhtml >}} <a href="/bibs/qcdc_isec2019.bib" target="_blank"><i class="fa fa-quote-right fa-lg"></i></a> <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8990965" target="_blank"><i class="far fa-file-pdf fa-lg"></i></a> {{< /rawhtml >}}

7. [[**ISVLSI 2019**](http://www.eng.ucy.ac.cy/theocharides/isvlsi19/)] **S. Kundu**, A. Fayyazi, Shahin Nazarian, Peter A. Beerel, Massoud Pedram, "**CSrram: Area-Efficient Low-Power Ex-Situ Training Framework for Memristive Neuromorphic Circuits Based on Clustered Sparsity**”.{{< rawhtml >}} <a href="/bibs/csrram_isvlsi2019.bib" target="_blank"><i class="fa fa-quote-right fa-lg"></i></a> <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8839473" target="_blank"><i class="far fa-file-pdf fa-lg"></i></a> {{< /rawhtml >}}

### Journals
1. [[**ACM Transactions on Embedded Computing Systems 2022**](https://dl.acm.org/journal/tecs)] **S. Kundu**, Y. Fu, Q. Sun, B. Ye, P. A. Beerel, M. Pedram, "**Towards Adversary aware Non-Iterative Model Pruning Through Dynamic Network Rewiring of DNNs**”.{{< rawhtml >}} <a href="/bibs/DNR_ACM_TECS2022.bib" target="_blank"><i class="fa fa-quote-right fa-lg"></i></a> <a href="https://dl.acm.org/doi/abs/10.1145/3510833" target="_blank"><i class="far fa-file-pdf fa-lg"></i></a> {{< /rawhtml >}}

2. [[**Frontiers in Neuroscience 2022**](https://www.frontiersin.org/journals/neuroscience)] G. Datta, **S. Kundu**, A. Jaiswal, P. A. Beerel, "**ACE-SNN: Algorithm-Hardware Co-design of Energy-Efficient & Low-Latency Deep Spiking Neural Networks for 3D Image Recognition**”.{{< rawhtml >}} <a href="https://www.frontiersin.org/articles/10.3389/fnins.2022.815258/full" target="_blank"><i class="far fa-file-pdf fa-lg"></i></a> {{< /rawhtml >}}

3. [[**Transactions on Computers 2020**](https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=12)] **S. Kundu**, M. Nazemi, M. Pedram, K. M. Chugg, P. A. Beerel, "**Pre-defined Sparsity for Low-Complexity
Convolutional Neural Networks**”.{{< rawhtml >}} <a href="/bibs/predefined_TC2020.bib" target="_blank"><i class="fa fa-quote-right fa-lg"></i></a> <a href="https://arxiv.org/pdf/2001.10710.pdf" target="_blank"><i class="far fa-file-pdf fa-lg"></i></a> <a href="https://github.com/ksouvik52/Pre-defined-sparseCNN" target="_blank"><i class="fab fa-github fa-lg"></i></a> {{< /rawhtml >}}

4. **S. Kundu**, G. Datta, M. Pedram, P. A. Beerel, "**Towards Low-Latency Energy-Efficient Deep SNNs via Attention-Guided Comp4ression**”, under review.

### Patents 
1. **[US Patent]** D.J. Cummings, J.P, Munoz, **S. Kundu**, S.N. Sridhar, M. Szankin, **"Machine Learning Model Scaling System with Energy Efficient Network Data Transfer for Power Aware Hardware"**.{{< rawhtml >}} <a href="https://patentimages.storage.googleapis.com/dd/e2/06/8057cf91bfcc86/US20220036123A1.pdf" target="_blank"><i class="far fa-file-pdf fa-lg"></i></a>{{< /rawhtml >}}

2. **[US Patent]** S. Sundaresan, **S. Kundu**, **''Deep neural network optimization system for machine learning model scaling"**.{{< rawhtml >}} <a href="https://patentimages.storage.googleapis.com/5a/bd/c4/1ed0cb0b3e9b30/US20220036194A1.pdf" target="_blank"><i class="far fa-file-pdf fa-lg"></i></a>{{< /rawhtml >}}